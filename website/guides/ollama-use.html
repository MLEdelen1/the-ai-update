<!doctype html>
<html lang="en">
<head><meta charset="UTF-8" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><title>Use Ollama Guide</title><link rel="stylesheet" href="../styles.css?v=11" /></head>
<body>
<canvas id="particles"></canvas><div class="top-glow"></div>
<nav id="nav"><div class="nav-wrap"><a href="../index.html" class="logo-group"><img src="../assets/logo.png" class="logo-img" alt=""><div class="logo-text">THE AI<span class="logo-accent">UPDATE</span></div></a><div class="nav-links" id="navLinks"><a href="../intel.html">Latest Intel</a><a href="../workflows.html">Workflows</a><a href="../tools.html">Tools</a><a href="index.html">Guides</a><a href="../articles.html">Articles</a><a href="../resources.html">Resources</a><a href="../starter-kit.html" class="nav-btn">Get Free Kit</a></div><button class="burger" onclick="document.getElementById('navLinks').classList.toggle('show')"><span></span><span></span><span></span></button></div></nav>
<main class="contain article-body" style="padding-top:100px">
<div class="sect-head"><p class="tag">USE GUIDE â€¢ OLLAMA</p><h1>Use Ollama after install</h1><p class="sect-sub">Learn the two most useful actions: local chat and local API call.</p></div>
<section class="intel-grid">
<article class="intel-card"><div class="intel-source">STEP 0</div><h3>Confirm model exists</h3><pre><code>ollama list</code></pre><p><strong>Expected result:</strong> You see at least one model, like llama3.2:3b.</p></article>
<article class="intel-card"><div class="intel-source">STEP 1</div><h3>Run a local prompt in terminal</h3><pre><code>ollama run llama3.2:3b "Write a 3-line shift handoff note for IT support."</code></pre><p><strong>Expected result:</strong> A short response appears in your terminal.</p></article>
<article class="intel-card"><div class="intel-source">STEP 2</div><h3>Call Ollama over local API</h3><pre><code>curl http://localhost:11434/api/generate -d '{"model":"llama3.2:3b","prompt":"Give one productivity tip for today.","stream":false}'</code></pre><p><strong>Expected result:</strong> JSON response with generated text.</p></article>
<article class="intel-card"><div class="intel-source">STEP 3</div><h3>Use a repeatable prompt template</h3><p>Use the same prompt structure each time: role, input, desired format.</p><p><strong>Expected result:</strong> More consistent local model output.</p></article>
</section>
<section class="tools-row"><article class="tool"><div class="tool-cat">IF NEEDED</div><h3>Install Ollama first</h3><p>Go back if models are missing or server is down.</p><a class="tool-link" href="ollama-setup.html">Open install guide â†’</a></article><article class="tool"><div class="tool-cat">NEXT</div><h3>Combine with OpenClaw + n8n</h3><p>Turn local responses into automated actions.</p><a class="tool-link" href="local-ai-stack.html">Open combine guide â†’</a></article></section>
</main>
<footer><div class="contain foot-inner"><div class="foot-brand"><img src="../assets/logo.png" class="foot-logo" alt=""><span>THE AI UPDATE</span></div><div class="foot-links"><a href="../index.html">Home</a><a href="index.html">Guides</a><a href="../articles.html">Articles</a><a href="../tools.html">Tools</a><a href="../resources.html">Resources</a><a href="../starter-kit.html">Starter Kit</a></div></div></footer><script src="../site.js"></script>
</body></html>

